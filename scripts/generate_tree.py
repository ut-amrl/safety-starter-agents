#!/usr/bin/env python

import numpy as np
import joblib
from safe_rl.utils.load_utils import load_policy
from safe_rl.utils.logx import EpochLogger
from sklearn.tree import DecisionTreeRegressor
import argparse
import io
from contextlib import redirect_stdout
import time

# Generate labeled data and pickle it by running the policy


def label_data(env, get_action, max_ep_len=None, num_episodes=100, render=False):
    '''Creates a set of training data for the sklearn decision tree regressor
    by running the policy forward to collect n training examples.

    Args:
        n: The number of training examples to generate.
        env: This the gym environment where we will run the policy
        get_action: a function that encapsulates the NN
        max_ep_len: Optional variable inidicating the tmax length of the episode
        num_episodes: Is the number of episodes that will be run

    Returns:
        Two lists of length n representing a set of observations and a
        corresponding set of actions that were generated by the policy.
    '''
    assert env is not None, "You done screwed up. Env is None"

    actions = []
    observations = []
    logger = EpochLogger()
    o, r, d, ep_ret, ep_cost, ep_len, n = env.reset(), 0, False, 0, 0, 0, 0

    while n < num_episodes:
        if render:
            env.render()
            time.sleep(1e-3)

        observations.append(o)
        a = get_action(o)
        a = np.clip(a, env.action_space.low, env.action_space.high)
        actions.append(a)
        o, r, d, info = env.step(a)
        ep_ret += r
        ep_cost += info.get('cost', 0)
        ep_len += 1

        if d or (ep_len == max_ep_len):
            logger.store(EpRet=ep_ret, EpCost=ep_cost, EpLen=ep_len)
            print('Episode %d \t EpRet %.3f \t EpCost %.3f \t EpLen %d' % (n, ep_ret, ep_cost, ep_len))
            o, r, d, ep_ret, ep_cost, ep_len = env.reset(), 0, False, 0, 0, 0
            n += 1

    # logger.log_tabular('EpRet', with_min_and_max=True)
    # logger.log_tabular('EpCost', with_min_and_max=True)
    # logger.log_tabular('EpLen', average_only=True)
    # logger.dump_tabular()
    f = io.StringIO()
    with redirect_stdout(f):
        logger.log_tabular('EpRet', with_min_and_max=True)
        logger.log_tabular('EpCost', with_min_and_max=True)
        logger.log_tabular('EpLen', average_only=True)
        logger.dump_tabular()
    out = f.getvalue()
    print(out)
    assert len(actions) == len(observations), "Your training data is not symmetrical" + \
        "The length of your actions is not equivalent to your number of observations."
    return observations, actions, out


def generate_tree(env, get_action, len, episodes, file_name, max_depth=0):
    '''Generates a decision tree regressor and pickles the regressor.
    '''
    all_observations, all_actions, nn_logs = label_data(env, get_action, len, episodes)
    tree_program = DecisionTreeRegressor() \
        if max_depth == 0 else DecisionTreeRegressor(max_depth=max_depth)
    tree_program.fit(all_observations, all_actions)

    print("Now rerunning the environment with the trained decision tree")
    # label_data(env, tree_program.predict, len, episodes)
    _, _, tree_logs = label_data(env, lambda a: tree_program.predict([a]), len, episodes)
    tree_and_data = {
                        'tree': tree_program,
                        'observations': all_observations,
                        'actions': all_actions,
                        'nn_logs': nn_logs,
                        'tree_logs': tree_logs
                    }
    full_name = str("tree_data_" + str(file_name) + ".pkl")
    joblib.dump(tree_and_data, full_name)


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('fpath', type=str)
    parser.add_argument('--len', '-l', type=int, default=0)
    parser.add_argument('--episodes', '-n', type=int, default=100)
    parser.add_argument('--itr', '-i', type=int, default=-1)
    parser.add_argument('--deterministic', '-d', action='store_true')
    parser.add_argument('--file_name', '-fn', type=str, default='')
    parser.add_argument('--max_depth', '-md', type=int, default=0)
    args = parser.parse_args()
    env, get_action, sess = load_policy(args.fpath, args.itr if args.itr >= 0 else 'last', args.deterministic)
    generate_tree(env, get_action, args.len, args.episodes, args.file_name, max_depth=args.max_depth)
